# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X53QRmiJIxfsnW67oOZzjSNIFV-XDWFl
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import matplotlib.pyplot as plt
import random
import torch.nn.functional as F
from collections import Counter
# %matplotlib inline

words = open('train.txt', 'r').read().splitlines()
words[:10]

#统计字符
char_counter = Counter(''.join(words))
chars = sorted(char_counter.keys())
chars

#创建字典
stoi = {s:i+1 for i,s in enumerate(chars)}
stoi['.'] = 0
itos = {i:s for s,i in stoi.items()}
len(itos)

#绘图
plt.figure(figsize=(20, 20))
num_chars = len(chars)
N = torch.zeros((num_chars, num_chars), dtype=torch.float32)



#文本数据转换成模型可以处理的格式
letter=3
random.seed(42)
random.shuffle(words)
X, Y = [], []
for w in words:
    for i in range(len(w)):
        context = [0] *  letter
        for j in range( letter):
            if i -  letter + j < 0:
                context[j] = 0
            else:
                context[j] = stoi[w[i -  letter + j]]
        X.append(context)
        Y.append(stoi[w[i]] if i < len(w) - 1 else stoi['.'])
X = torch.tensor(X)
Y = torch.tensor(Y)
print(X.shape, Y.shape,X,Y)

C = torch.randn((len(itos), 2))
plt.figure(figsize=(10,10))
plt.scatter(C[:,0].data, C[:,1].data, s=200)
for i in range(C.shape[0]):
    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha="center", va="center", color='white')

#前向传播计算
sr = C[X]
w1 = torch.randn((6, 100))
b1 = torch.randn(100)
h = torch.tanh(sr.view(-1, 6) @ w1 + b1)
w2 = torch.randn((100, len(itos)))
b2 = torch.randn(len(itos))
logits = h @ w2 + b2
prob = F.softmax(logits, dim=1)
prob

counts = logits.exp()
prob = counts / counts.sum(1, keepdims=True)
prob

#设置简单神经网络
seed = random.randint(0, 2**32 - 1)
g = torch.Generator().manual_seed(seed)
C = torch.randn((len(itos), 10), generator=g)
w1 = torch.randn((30, 200), generator=g)
b1 = torch.randn(200, generator=g)
w2 = torch.randn((200, len(itos)), generator=g)
b2 = torch.randn(len(itos), generator=g)
parameters = [C, w1, b1, w2, b2]
for i in parameters:
  i.requires_grad = True

losses = []
stepes = []

for i in range(1000):
  # 小批量
  ix = torch.randint(0, X.shape[0], (20,))
  # 前向传播
  sr = C[X[ix]]
  h = torch.tanh(sr.view(-1, 30) @ w1 + b1)
  logits = h @ w2 + b2
  loss = F.cross_entropy(logits, Y[ix])
  # 后向传播
  for i in parameters:
    p.grad = None
  loss.backward()

  lr = 0.1 if i < 500 else 0.01
  for i in parameters:
    p.data += -lr * p.grad
  stepes.append(i)
  losses.append(loss.log10().item())



sr = C[X]
h = torch.tanh(sr.view(-1, 30) @ w1 + b1)
logits = h @ w2 + b2
loss = F.cross_entropy(logits, Y)

#绘图
plt.figure(figsize=(8,8))
plt.scatter(C[:,0].data, C[:,1].data, s=200)
for i in range(C.shape[0]):
    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha="center", va="center", color='white')

torch.save({'C': C, 'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2}, 'model.torch')